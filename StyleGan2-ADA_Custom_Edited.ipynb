{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HRiloKiRwOuI"
   },
   "outputs": [],
   "source": [
    "# https://github.com/dvschultz/ml-art-colabs/blob/master/Stylegan2_ada_Custom_Training.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)]()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bopj6CtXwZvV"
   },
   "source": [
    "# <b> Custom Training StyleGan2-ADA </b>\n",
    "StyleGAN2-ADA only work with Tensorflow 1. Run the next cell before anything else to make sure we’re using TF1 and not TF2.\n",
    "\n",
    "You're going to need at least 12 GB of RAM for the stylegan-2 to run. With Google Collab, you'd need pro or pro plus unfortunatley."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 366
    },
    "executionInfo": {
     "elapsed": 6811,
     "status": "ok",
     "timestamp": 1647745357482,
     "user": {
      "displayName": "Spencer Pao",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjBRhLUmbzlcfhNxDcKTG31uPEUUXWErPI_XDmoMA=s64",
      "userId": "16613243337035502990"
     },
     "user_tz": 240
    },
    "id": "M_NrKnjoojez",
    "outputId": "a45c6db9-45dc-4f0e-c926-63e9750192e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.19.5\n",
      "  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.8 MB 15.4 MB/s \n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.21.5\n",
      "    Uninstalling numpy-1.21.5:\n",
      "      Successfully uninstalled numpy-1.21.5\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n",
      "tensorflow 2.8.0 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
      "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
      "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
      "Successfully installed numpy-1.19.5\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "numpy"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install numpy==1.19.5 # For some reason, need to downgrade to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 337,
     "status": "ok",
     "timestamp": 1647745366008,
     "user": {
      "displayName": "Spencer Pao",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjBRhLUmbzlcfhNxDcKTG31uPEUUXWErPI_XDmoMA=s64",
      "userId": "16613243337035502990"
     },
     "user_tz": 240
    },
    "id": "IkBMatYUwYU_",
    "outputId": "c053c387-2331-4d3b-dfd4-163b1c01dfac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 1.x selected.\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 1.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2540,
     "status": "ok",
     "timestamp": 1647745371743,
     "user": {
      "displayName": "Spencer Pao",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjBRhLUmbzlcfhNxDcKTG31uPEUUXWErPI_XDmoMA=s64",
      "userId": "16613243337035502990"
     },
     "user_tz": 240
    },
    "id": "JkzMDN_qgFjf",
    "outputId": "01e0aaea-5994-4386-ca37-5c9896a84bab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tensorflow\n",
      "Version: 1.15.2\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
      "Home-page: https://www.tensorflow.org/\n",
      "Author: Google Inc.\n",
      "Author-email: packages@tensorflow.org\n",
      "License: Apache 2.0\n",
      "Location: /tensorflow-1.15.2/python3.7\n",
      "Requires: grpcio, google-pasta, tensorflow-estimator, keras-applications, numpy, absl-py, protobuf, opt-einsum, six, tensorboard, gast, wrapt, termcolor, wheel, keras-preprocessing, astor\n",
      "Required-by: stable-baselines, magenta, kapre\n"
     ]
    }
   ],
   "source": [
    "!pip show tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1647745371743,
     "user": {
      "displayName": "Spencer Pao",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjBRhLUmbzlcfhNxDcKTG31uPEUUXWErPI_XDmoMA=s64",
      "userId": "16613243337035502990"
     },
     "user_tz": 240
    },
    "id": "8nzRy8sjwYaE",
    "outputId": "1514df61-da23-4d16-af8a-741c6d9018bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Mar 20 03:02:52 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   34C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kuypHwwuwmsV"
   },
   "source": [
    "# <b> Install Repo to Google Drive </b>\n",
    "Colab is a little funky with training. I’ve found the best way to do this is to install the repo directly into your Google Drive folder.\n",
    "\n",
    "First, mount your Drive to the Colab notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16719,
     "status": "ok",
     "timestamp": 1647745392944,
     "user": {
      "displayName": "Spencer Pao",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjBRhLUmbzlcfhNxDcKTG31uPEUUXWErPI_XDmoMA=s64",
      "userId": "16613243337035502990"
     },
     "user_tz": 240
    },
    "id": "fqNWuFA-wYfm",
    "outputId": "a77b1287-996e-4ade-e4dc-a7f07ab78334"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fLbNh6sGwtPl"
   },
   "source": [
    "Next, run this cell. If you’re already installed the repo, it will skip the installation process and change into the repo’s directory. If you haven’t installed it, it will install all the files necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 254,
     "status": "ok",
     "timestamp": 1647745393195,
     "user": {
      "displayName": "Spencer Pao",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjBRhLUmbzlcfhNxDcKTG31uPEUUXWErPI_XDmoMA=s64",
      "userId": "16613243337035502990"
     },
     "user_tz": 240
    },
    "id": "ZGpz2dZEwYif",
    "outputId": "cc4999a2-6ade-451c-e7fd-d519504f1cf6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/colab-sg2-ada/stylegan2-ada\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if os.path.isdir(\"/content/drive/My Drive/colab-sg2-ada\"):\n",
    "    %cd \"/content/drive/My Drive/colab-sg2-ada/stylegan2-ada\"\n",
    "else:\n",
    "    #install script\n",
    "    %cd \"/content/drive/My Drive/\"\n",
    "    !mkdir colab-sg2-ada\n",
    "    %cd colab-sg2-ada\n",
    "    !git clone https://github.com/dvschultz/stylegan2-ada\n",
    "    %cd stylegan2-ada\n",
    "    !mkdir downloads\n",
    "    !mkdir datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9374,
     "status": "ok",
     "timestamp": 1647745402568,
     "user": {
      "displayName": "Spencer Pao",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjBRhLUmbzlcfhNxDcKTG31uPEUUXWErPI_XDmoMA=s64",
      "userId": "16613243337035502990"
     },
     "user_tz": 240
    },
    "id": "CR2GzHYzwYla",
    "outputId": "61bd3213-55ae-4be0-d764-d279072054ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/colab-sg2-ada/stylegan2-ada\n"
     ]
    }
   ],
   "source": [
    "%cd \"/content/drive/My Drive/colab-sg2-ada/stylegan2-ada\"\n",
    "!git config --global user.name \"test\"\n",
    "!git config --global user.email \"test@test.com\"\n",
    "!git fetch origin\n",
    "!git checkout origin/main -- train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GCn4ktskwwhp"
   },
   "source": [
    "# <b> Convert dataset to .tfrecords </b>\n",
    "<i> Note: You only need to do this once per dataset. If you have already run this and are returning to conntinue training, skip these cells. </i>\n",
    "\n",
    "Next we need to convert our image dataset to a format that StyleGAN2-ADA can read from. There are two options here. You can upload your dataset directly to Colab (as a zipped file), or you can upload it to Drive directly and read it from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vTYlTsfPwYon"
   },
   "outputs": [],
   "source": [
    "# # #if you manually uploaded your dataset to Colab, unzip it\n",
    "# zip_path = \"/content/CAT1024.zip\"\n",
    "\n",
    "# !unzip {zip_path} -d /content/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tlvI9qJXw3Yd"
   },
   "source": [
    "Now that your image dataset is uploaded, we need to convert it to the .tfrecords format.\n",
    "\n",
    "Depending on the resolution of your images and how many you have, this can take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "executionInfo": {
     "elapsed": 17774905,
     "status": "ok",
     "timestamp": 1647627528036,
     "user": {
      "displayName": "Spencer Pao",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjBRhLUmbzlcfhNxDcKTG31uPEUUXWErPI_XDmoMA=s64",
      "userId": "16613243337035502990"
     },
     "user_tz": 240
    },
    "id": "YxOxOF0Ow2io",
    "outputId": "6cc955a5-aecd-46af-e2bf-5f37807d4c8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from \"/content/drive/MyDrive/artists\"\n",
      "Creating dataset \"./datasets/artists_tf\"\n",
      "dataset_tool.py:97: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  'data': tf.train.Feature(bytes_list=tf.train.BytesList(value=[quant.tostring()]))}))\n",
      "Added 21309 images.\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"NOTE: I move the ./datasets/dataset_name/ to drive/My Drive so I don't have to rerun this cell.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#update this to the path to your image folder\n",
    "dataset_path = \"/content/drive/MyDrive/artists\" #/content/drive/MyDrive/abstract abstract_tf for entire ~7500 images.\n",
    "\n",
    "#give your dataset a name\n",
    "dataset_name = \"artists_tf\" #abstract_tf for entire ~7500 images.\n",
    "\n",
    "#you don't need to edit anything here\n",
    "!python dataset_tool.py create_from_images ./datasets/{dataset_name} {dataset_path}\n",
    "\n",
    "\"\"\"NOTE: I move the ./datasets/dataset_name/ to drive/My Drive so I don't have to rerun this cell.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tCKzr3Q7w5mj"
   },
   "source": [
    "<b> Train a custom model </b>\n",
    "We’re ready to start training! There are numerous arguments to training, what’s listed below are the most popular options. To see all the options, run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12865,
     "status": "ok",
     "timestamp": 1647627613447,
     "user": {
      "displayName": "Spencer Pao",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjBRhLUmbzlcfhNxDcKTG31uPEUUXWErPI_XDmoMA=s64",
      "userId": "16613243337035502990"
     },
     "user_tz": 240
    },
    "id": "7FIddY_8w2k9",
    "outputId": "0c64e341-ef2c-493f-aa6e-347ba33fe88b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: train.py [-h] --outdir DIR [--gpus INT] [--snap INT] [--seed INT] [-n]\n",
      "                --data PATH [--res INT] [--mirror BOOL] [--mirrory BOOL]\n",
      "                [--use-raw BOOL] [--metrics LIST] [--metricdata PATH]\n",
      "                [--cfg {auto,11gb-gpu,11gb-gpu-complex,24gb-gpu,24gb-gpu-complex,48gb-gpu,48gb-2gpu,stylegan2,paper256,paper512,paper1024,cifar,cifarbaseline,aydao}]\n",
      "                [--lrate FLOAT] [--ttur BOOL] [--gamma FLOAT] [--nkimg INT]\n",
      "                [--kimg INT] [--topk FLOAT] [--aug {noaug,ada,fixed,adarv}]\n",
      "                [--p FLOAT] [--target TARGET] [--initstrength INITSTRENGTH]\n",
      "                [--augpipe {blit,geom,color,filter,noise,cutout,bg,bgc,bgcf,bgcfn,bgcfnc}]\n",
      "                [--cmethod {nocmethod,bcr,zcr,pagan,wgangp,auxrot,spectralnorm,shallowmap,adropout}]\n",
      "                [--dcap FLOAT] [--resume RESUME] [--freezed INT]\n",
      "\n",
      "Train a GAN using the techniques described in the paper\n",
      "\"Training Generative Adversarial Networks with Limited Data\".\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "\n",
      "general options:\n",
      "  --outdir DIR          Where to save the results (required)\n",
      "  --gpus INT            Number of GPUs to use (default: 1 gpu)\n",
      "  --snap INT            Snapshot interval (default: 50 ticks)\n",
      "  --seed INT            Random seed (default: 1000)\n",
      "  -n, --dry-run         Print training options and exit\n",
      "\n",
      "training dataset:\n",
      "  --data PATH           Training dataset path (required)\n",
      "  --res INT             Dataset resolution (default: highest available)\n",
      "  --mirror BOOL         Augment dataset with x-flips (default: false)\n",
      "  --mirrory BOOL        Augment dataset with y-flips (default: false)\n",
      "  --use-raw BOOL        Use raw image dataset, i.e. created from\n",
      "                        create_from_images_raw (default: False)\n",
      "\n",
      "metrics:\n",
      "  --metrics LIST        Comma-separated list or \"none\" (default: fid50k_full)\n",
      "  --metricdata PATH     Dataset to evaluate metrics against (optional)\n",
      "\n",
      "base config:\n",
      "  --cfg {auto,11gb-gpu,11gb-gpu-complex,24gb-gpu,24gb-gpu-complex,48gb-gpu,48gb-2gpu,stylegan2,paper256,paper512,paper1024,cifar,cifarbaseline,aydao}\n",
      "                        Base config (default: auto)\n",
      "  --lrate FLOAT         Override learning rate\n",
      "  --ttur BOOL           Use Two Time-Scale Update Rule (double learning rate\n",
      "                        for discriminator) (default: false)\n",
      "  --gamma FLOAT         Override R1 gamma\n",
      "  --nkimg INT           Override starting count\n",
      "  --kimg INT            Override training duration\n",
      "  --topk FLOAT          utilize top-k training\n",
      "\n",
      "discriminator augmentation:\n",
      "  --aug {noaug,ada,fixed,adarv}\n",
      "                        Augmentation mode (default: ada)\n",
      "  --p FLOAT             Specify augmentation probability for --aug=fixed\n",
      "  --target TARGET       Override ADA target for --aug=ada and --aug=adarv\n",
      "  --initstrength INITSTRENGTH\n",
      "                        Override ADA strength at start\n",
      "  --augpipe {blit,geom,color,filter,noise,cutout,bg,bgc,bgcf,bgcfn,bgcfnc}\n",
      "                        Augmentation pipeline (default: bgc)\n",
      "\n",
      "comparison methods:\n",
      "  --cmethod {nocmethod,bcr,zcr,pagan,wgangp,auxrot,spectralnorm,shallowmap,adropout}\n",
      "                        Comparison method (default: nocmethod)\n",
      "  --dcap FLOAT          Multiplier for discriminator capacity\n",
      "\n",
      "transfer learning:\n",
      "  --resume RESUME       Resume from network pickle (default: noresume)\n",
      "  --freezed INT         Freeze-D (default: 0 discriminator layers)\n",
      "\n",
      "examples:\n",
      "\n",
      "  # Train custom dataset using 1 GPU.\n",
      "  python train.py --outdir=~/training-runs --gpus=1 --data=~/datasets/custom\n",
      "\n",
      "  # Train class-conditional CIFAR-10 using 2 GPUs.\n",
      "  python train.py --outdir=~/training-runs --gpus=2 --data=~/datasets/cifar10c \\\n",
      "      --cfg=cifar\n",
      "\n",
      "  # Transfer learn MetFaces from FFHQ using 4 GPUs.\n",
      "  python train.py --outdir=~/training-runs --gpus=4 --data=~/datasets/metfaces \\\n",
      "      --cfg=paper1024 --mirror=1 --resume=ffhq1024 --snap=10\n",
      "\n",
      "  # Reproduce original StyleGAN2 config F.\n",
      "  python train.py --outdir=~/training-runs --gpus=8 --data=~/datasets/ffhq \\\n",
      "      --cfg=stylegan2 --res=1024 --mirror=1 --aug=noaug\n",
      "\n",
      "available base configs (--cfg):\n",
      "  auto           Automatically select reasonable defaults based on resolution\n",
      "                 and GPU count. Good starting point for new datasets.\n",
      "  stylegan2      Reproduce results for StyleGAN2 config F at 1024x1024.\n",
      "  paper256       Reproduce results for FFHQ and LSUN Cat at 256x256.\n",
      "  paper512       Reproduce results for BreCaHAD and AFHQ at 512x512.\n",
      "  paper1024      Reproduce results for MetFaces at 1024x1024.\n",
      "  cifar          Reproduce results for CIFAR-10 (tuned configuration).\n",
      "  cifarbaseline  Reproduce results for CIFAR-10 (baseline configuration).\n",
      "\n",
      "transfer learning source networks (--resume):\n",
      "  ffhq256        FFHQ trained at 256x256 resolution.\n",
      "  ffhq512        FFHQ trained at 512x512 resolution.\n",
      "  ffhq1024       FFHQ trained at 1024x1024 resolution.\n",
      "  celebahq256    CelebA-HQ trained at 256x256 resolution.\n",
      "  lsundog256     LSUN Dog trained at 256x256 resolution.\n",
      "  afhqcat512     AFHQ Cat trained at 512x512 resolution.\n",
      "  afhqdog512     AFHQ Dog trained at 512x512 resolution.\n",
      "  afhqwild512    AFHQ Wild trained at 512x512 resolution.\n",
      "  brecahad512    BreCaHAD trained at 512x512 resolution.\n",
      "  cifar10        CIFAR10 trained at 32x32 resolution.\n",
      "  metfaces512    MetFaces trained at 512x512 resolution.\n",
      "  <path or URL>  Custom network pickle.\n"
     ]
    }
   ],
   "source": [
    "!python train.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "aMVczuUtw2nf",
    "outputId": "9e60c644-3643-41d7-bb41-eb681edf74f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tcmalloc: large alloc 4294967296 bytes == 0x55990819e000 @  0x7fec2ca90001 0x7fec29c9354f 0x7fec29ce3b58 0x7fec29ce7b17 0x7fec29d86203 0x559900000424 0x559900000120 0x559900074b80 0x55990006f66e 0x55990000236c 0x5599000437b9 0x5599000406d4 0x559900000c29 0x559900074e61 0x55990006f02f 0x5598fff40e2b 0x559900071633 0x55990006f02f 0x5598fff40e2b 0x559900071633 0x55990006f66e 0x5598fff40e2b 0x559900071633 0x5599000019da 0x55990006feae 0x55990006f02f 0x55990006ed43 0x559900139302 0x55990013967d 0x559900139526 0x5599001111d3\n",
      "tcmalloc: large alloc 4294967296 bytes == 0x559a0819e000 @  0x7fec2ca8e1e7 0x7fec29c9346e 0x7fec29ce3c7b 0x7fec29ce435f 0x7fec29d86103 0x559900000424 0x559900000120 0x559900074b80 0x55990006f02f 0x559900001aba 0x559900070cd4 0x55990006f02f 0x559900001aba 0x559900070cd4 0x55990006f02f 0x559900001aba 0x559900070cd4 0x5599000019da 0x55990006feae 0x55990006f02f 0x559900001aba 0x5599000742c0 0x55990006f02f 0x559900001aba 0x559900070cd4 0x55990006f66e 0x55990000236c 0x5599000437b9 0x5599000406d4 0x559900000c29 0x559900074e61\n",
      "tcmalloc: large alloc 4294967296 bytes == 0x559b09486000 @  0x7fec2ca8e1e7 0x7fec29c9346e 0x7fec29ce3c7b 0x7fec29ce435f 0x7febb368f235 0x7febb3012792 0x7febb3012d42 0x7febb2fcbaee 0x559900000317 0x559900000120 0x559900074679 0x5599000019da 0x559900070108 0x55990006f1c0 0x5598fff40eb0 0x559900071633 0x55990006f02f 0x559900001aba 0x559900070108 0x55990006f66e 0x559900001aba 0x559900070108 0x5599000019da 0x559900070108 0x55990006f02f 0x559900002151 0x559900002571 0x559900071633 0x55990006f02f 0x559900001aba 0x55990006feae\n",
      "\n",
      "Training options:\n",
      "{\n",
      "  \"G_args\": {\n",
      "    \"func_name\": \"training.networks.G_main\",\n",
      "    \"fmap_base\": 16384,\n",
      "    \"fmap_max\": 512,\n",
      "    \"mapping_layers\": 8,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"D_args\": {\n",
      "    \"func_name\": \"training.networks.D_main\",\n",
      "    \"mbstd_group_size\": 4,\n",
      "    \"fmap_base\": 16384,\n",
      "    \"fmap_max\": 512,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"G_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.002\n",
      "  },\n",
      "  \"D_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.002\n",
      "  },\n",
      "  \"loss_args\": {\n",
      "    \"func_name\": \"training.loss.stylegan2\",\n",
      "    \"r1_gamma\": 10\n",
      "  },\n",
      "  \"augment_args\": {\n",
      "    \"class_name\": \"training.augment.AdaptiveAugment\",\n",
      "    \"tune_heuristic\": \"rt\",\n",
      "    \"tune_target\": 0.6,\n",
      "    \"apply_func\": \"training.augment.augment_pipeline\",\n",
      "    \"apply_args\": {\n",
      "      \"xflip\": 1,\n",
      "      \"rotate90\": 1,\n",
      "      \"xint\": 1,\n",
      "      \"scale\": 1,\n",
      "      \"rotate\": 1,\n",
      "      \"aniso\": 1,\n",
      "      \"xfrac\": 1,\n",
      "      \"brightness\": 1,\n",
      "      \"contrast\": 1,\n",
      "      \"lumaflip\": 1,\n",
      "      \"hue\": 1,\n",
      "      \"saturation\": 1,\n",
      "      \"imgfilter\": 1,\n",
      "      \"noise\": 1,\n",
      "      \"cutout\": 1\n",
      "    },\n",
      "    \"tune_kimg\": 100\n",
      "  },\n",
      "  \"num_gpus\": 1,\n",
      "  \"image_snapshot_ticks\": 5,\n",
      "  \"network_snapshot_ticks\": 5,\n",
      "  \"train_dataset_args\": {\n",
      "    \"path\": \"/content/drive/MyDrive/artists_tf\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"use_raw\": false,\n",
      "    \"resolution\": 1024,\n",
      "    \"mirror_augment\": true,\n",
      "    \"mirror_augment_v\": true\n",
      "  },\n",
      "  \"metric_arg_list\": [],\n",
      "  \"metric_dataset_args\": {\n",
      "    \"path\": \"/content/drive/MyDrive/artists_tf\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"use_raw\": false,\n",
      "    \"resolution\": 1024,\n",
      "    \"mirror_augment\": true,\n",
      "    \"mirror_augment_v\": true\n",
      "  },\n",
      "  \"total_kimg\": 25000,\n",
      "  \"minibatch_size\": 4,\n",
      "  \"minibatch_gpu\": 4,\n",
      "  \"G_smoothing_kimg\": 10,\n",
      "  \"G_smoothing_rampup\": null,\n",
      "  \"resume_pkl\": \"/content/drive/MyDrive/results_artists_gan/00002-artists_tf-mirror-mirrory-11gb-gpu-bgcfnc-resumecustom/network-snapshot-000060.pkl\",\n",
      "  \"run_dir\": \"/content/drive/MyDrive/results_artists_gan/00003-artists_tf-mirror-mirrory-11gb-gpu-bgcfnc-resumecustom\"\n",
      "}\n",
      "\n",
      "Output directory:  /content/drive/MyDrive/results_artists_gan/00003-artists_tf-mirror-mirrory-11gb-gpu-bgcfnc-resumecustom\n",
      "Training data:     /content/drive/MyDrive/artists_tf\n",
      "Training length:   25000 kimg\n",
      "Resolution:        1024\n",
      "Number of GPUs:    1\n",
      "\n",
      "Creating output directory...\n",
      "Loading training set...\n",
      "tcmalloc: large alloc 4294967296 bytes == 0x559907e9c000 @  0x7fec2ca90001 0x7fec29c9354f 0x7fec29ce3b58 0x7fec29ce7b17 0x7fec29d86203 0x559900000424 0x559900000120 0x559900074b80 0x55990006f66e 0x55990000236c 0x5599000437b9 0x5599000406d4 0x559900000c29 0x559900074e61 0x55990006f02f 0x5598fff40e2b 0x559900071633 0x55990006f02f 0x5598fff40e2b 0x559900071633 0x55990006f66e 0x5598fff40e2b 0x559900071633 0x5599000019da 0x55990006feae 0x55990006f02f 0x55990006ed43 0x559900139302 0x55990013967d 0x559900139526 0x5599001111d3\n",
      "tcmalloc: large alloc 4294967296 bytes == 0x559c09486000 @  0x7fec2ca8e1e7 0x7fec29c9346e 0x7fec29ce3c7b 0x7fec29ce435f 0x7fec29d86103 0x559900000424 0x559900000120 0x559900074b80 0x55990006f02f 0x559900001aba 0x559900070cd4 0x55990006f02f 0x559900001aba 0x559900070cd4 0x55990006f02f 0x559900001aba 0x559900070cd4 0x5599000019da 0x55990006feae 0x55990006f02f 0x559900001aba 0x5599000742c0 0x55990006f02f 0x559900001aba 0x559900070cd4 0x55990006f66e 0x55990000236c 0x5599000437b9 0x5599000406d4 0x559900000c29 0x559900074e61\n",
      "tcmalloc: large alloc 4294967296 bytes == 0x559c09486000 @  0x7fec2ca8e1e7 0x7fec29c9346e 0x7fec29ce3c7b 0x7fec29ce435f 0x7febb368f235 0x7febb3012792 0x7febb3012d42 0x7febb2fcbaee 0x559900000317 0x559900000120 0x559900074679 0x5599000019da 0x559900070108 0x55990006f1c0 0x5598fff40eb0 0x559900071633 0x55990006f02f 0x559900001aba 0x559900070108 0x55990006f66e 0x559900001aba 0x559900070108 0x5599000019da 0x559900070108 0x55990006f02f 0x559900002151 0x559900002571 0x559900071633 0x55990006f02f 0x559900001aba 0x55990006feae\n",
      "Image shape: [3, 1024, 1024]\n",
      "Label shape: [0]\n",
      "\n",
      "Constructing networks...\n",
      "Setting up TensorFlow plugin \"fused_bias_act.cu\": Compiling... Loading... Done.\n",
      "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Compiling... Loading... Done.\n",
      "Resuming from \"/content/drive/MyDrive/results_artists_gan/00002-artists_tf-mirror-mirrory-11gb-gpu-bgcfnc-resumecustom/network-snapshot-000060.pkl\"\n",
      "\n",
      "G                               Params    OutputShape          WeightShape     \n",
      "---                             ---       ---                  ---             \n",
      "latents_in                      -         (?, 512)             -               \n",
      "labels_in                       -         (?, 0)               -               \n",
      "epochs                          1         ()                   ()              \n",
      "epochs_1                        1         ()                   ()              \n",
      "G_mapping/Normalize             -         (?, 512)             -               \n",
      "G_mapping/Dense0                262656    (?, 512)             (512, 512)      \n",
      "G_mapping/Dense1                262656    (?, 512)             (512, 512)      \n",
      "G_mapping/Dense2                262656    (?, 512)             (512, 512)      \n",
      "G_mapping/Dense3                262656    (?, 512)             (512, 512)      \n",
      "G_mapping/Dense4                262656    (?, 512)             (512, 512)      \n",
      "G_mapping/Dense5                262656    (?, 512)             (512, 512)      \n",
      "G_mapping/Dense6                262656    (?, 512)             (512, 512)      \n",
      "G_mapping/Dense7                262656    (?, 512)             (512, 512)      \n",
      "G_mapping/Broadcast             -         (?, 18, 512)         -               \n",
      "dlatent_avg                     -         (512,)               -               \n",
      "Truncation/Lerp                 -         (?, 18, 512)         -               \n",
      "G_synthesis/4x4/Const           8192      (?, 512, 4, 4)       (1, 512, 4, 4)  \n",
      "G_synthesis/4x4/Conv            2622465   (?, 512, 4, 4)       (3, 3, 512, 512)\n",
      "G_synthesis/4x4/ToRGB           264195    (?, 3, 4, 4)         (1, 1, 512, 3)  \n",
      "G_synthesis/8x8/Conv0_up        2622465   (?, 512, 8, 8)       (3, 3, 512, 512)\n",
      "G_synthesis/8x8/Conv1           2622465   (?, 512, 8, 8)       (3, 3, 512, 512)\n",
      "G_synthesis/8x8/Upsample        -         (?, 3, 8, 8)         -               \n",
      "G_synthesis/8x8/ToRGB           264195    (?, 3, 8, 8)         (1, 1, 512, 3)  \n",
      "G_synthesis/16x16/Conv0_up      2622465   (?, 512, 16, 16)     (3, 3, 512, 512)\n",
      "G_synthesis/16x16/Conv1         2622465   (?, 512, 16, 16)     (3, 3, 512, 512)\n",
      "G_synthesis/16x16/Upsample      -         (?, 3, 16, 16)       -               \n",
      "G_synthesis/16x16/ToRGB         264195    (?, 3, 16, 16)       (1, 1, 512, 3)  \n",
      "G_synthesis/32x32/Conv0_up      2622465   (?, 512, 32, 32)     (3, 3, 512, 512)\n",
      "G_synthesis/32x32/Conv1         2622465   (?, 512, 32, 32)     (3, 3, 512, 512)\n",
      "G_synthesis/32x32/Upsample      -         (?, 3, 32, 32)       -               \n",
      "G_synthesis/32x32/ToRGB         264195    (?, 3, 32, 32)       (1, 1, 512, 3)  \n",
      "G_synthesis/64x64/Conv0_up      2622465   (?, 512, 64, 64)     (3, 3, 512, 512)\n",
      "G_synthesis/64x64/Conv1         2622465   (?, 512, 64, 64)     (3, 3, 512, 512)\n",
      "G_synthesis/64x64/Upsample      -         (?, 3, 64, 64)       -               \n",
      "G_synthesis/64x64/ToRGB         264195    (?, 3, 64, 64)       (1, 1, 512, 3)  \n",
      "G_synthesis/128x128/Conv0_up    1442561   (?, 256, 128, 128)   (3, 3, 512, 256)\n",
      "G_synthesis/128x128/Conv1       721409    (?, 256, 128, 128)   (3, 3, 256, 256)\n",
      "G_synthesis/128x128/Upsample    -         (?, 3, 128, 128)     -               \n",
      "G_synthesis/128x128/ToRGB       132099    (?, 3, 128, 128)     (1, 1, 256, 3)  \n",
      "G_synthesis/256x256/Conv0_up    426369    (?, 128, 256, 256)   (3, 3, 256, 128)\n",
      "G_synthesis/256x256/Conv1       213249    (?, 128, 256, 256)   (3, 3, 128, 128)\n",
      "G_synthesis/256x256/Upsample    -         (?, 3, 256, 256)     -               \n",
      "G_synthesis/256x256/ToRGB       66051     (?, 3, 256, 256)     (1, 1, 128, 3)  \n",
      "G_synthesis/512x512/Conv0_up    139457    (?, 64, 512, 512)    (3, 3, 128, 64) \n",
      "G_synthesis/512x512/Conv1       69761     (?, 64, 512, 512)    (3, 3, 64, 64)  \n",
      "G_synthesis/512x512/Upsample    -         (?, 3, 512, 512)     -               \n",
      "G_synthesis/512x512/ToRGB       33027     (?, 3, 512, 512)     (1, 1, 64, 3)   \n",
      "G_synthesis/1024x1024/Conv0_up  51297     (?, 32, 1024, 1024)  (3, 3, 64, 32)  \n",
      "G_synthesis/1024x1024/Conv1     25665     (?, 32, 1024, 1024)  (3, 3, 32, 32)  \n",
      "G_synthesis/1024x1024/Upsample  -         (?, 3, 1024, 1024)   -               \n",
      "G_synthesis/1024x1024/ToRGB     16515     (?, 3, 1024, 1024)   (1, 1, 32, 3)   \n",
      "---                             ---       ---                  ---             \n",
      "Total                           30370062                                       \n",
      "\n",
      "\n",
      "D                     Params    OutputShape          WeightShape     \n",
      "---                   ---       ---                  ---             \n",
      "images_in             -         (?, 3, 1024, 1024)   -               \n",
      "labels_in             -         (?, 0)               -               \n",
      "1024x1024/FromRGB     128       (?, 32, 1024, 1024)  (1, 1, 3, 32)   \n",
      "1024x1024/Conv0       9248      (?, 32, 1024, 1024)  (3, 3, 32, 32)  \n",
      "1024x1024/Conv1_down  18496     (?, 64, 512, 512)    (3, 3, 32, 64)  \n",
      "1024x1024/Skip        2048      (?, 64, 512, 512)    (1, 1, 32, 64)  \n",
      "512x512/Conv0         36928     (?, 64, 512, 512)    (3, 3, 64, 64)  \n",
      "512x512/Conv1_down    73856     (?, 128, 256, 256)   (3, 3, 64, 128) \n",
      "512x512/Skip          8192      (?, 128, 256, 256)   (1, 1, 64, 128) \n",
      "256x256/Conv0         147584    (?, 128, 256, 256)   (3, 3, 128, 128)\n",
      "256x256/Conv1_down    295168    (?, 256, 128, 128)   (3, 3, 128, 256)\n",
      "256x256/Skip          32768     (?, 256, 128, 128)   (1, 1, 128, 256)\n",
      "128x128/Conv0         590080    (?, 256, 128, 128)   (3, 3, 256, 256)\n",
      "128x128/Conv1_down    1180160   (?, 512, 64, 64)     (3, 3, 256, 512)\n",
      "128x128/Skip          131072    (?, 512, 64, 64)     (1, 1, 256, 512)\n",
      "64x64/Conv0           2359808   (?, 512, 64, 64)     (3, 3, 512, 512)\n",
      "64x64/Conv1_down      2359808   (?, 512, 32, 32)     (3, 3, 512, 512)\n",
      "64x64/Skip            262144    (?, 512, 32, 32)     (1, 1, 512, 512)\n",
      "32x32/Conv0           2359808   (?, 512, 32, 32)     (3, 3, 512, 512)\n",
      "32x32/Conv1_down      2359808   (?, 512, 16, 16)     (3, 3, 512, 512)\n",
      "32x32/Skip            262144    (?, 512, 16, 16)     (1, 1, 512, 512)\n",
      "16x16/Conv0           2359808   (?, 512, 16, 16)     (3, 3, 512, 512)\n",
      "16x16/Conv1_down      2359808   (?, 512, 8, 8)       (3, 3, 512, 512)\n",
      "16x16/Skip            262144    (?, 512, 8, 8)       (1, 1, 512, 512)\n",
      "8x8/Conv0             2359808   (?, 512, 8, 8)       (3, 3, 512, 512)\n",
      "8x8/Conv1_down        2359808   (?, 512, 4, 4)       (3, 3, 512, 512)\n",
      "8x8/Skip              262144    (?, 512, 4, 4)       (1, 1, 512, 512)\n",
      "4x4/MinibatchStddev   -         (?, 513, 4, 4)       -               \n",
      "4x4/Conv              2364416   (?, 512, 4, 4)       (3, 3, 513, 512)\n",
      "4x4/Dense0            4194816   (?, 512)             (8192, 512)     \n",
      "Output                513       (?, 1)               (512, 1)        \n",
      "---                   ---       ---                  ---             \n",
      "Total                 29012513                                       \n",
      "\n",
      "Exporting sample images...\n",
      "Replicating networks across 1 GPUs...\n",
      "Initializing augmentations...\n",
      "Setting up optimizers...\n",
      "Constructing training graph...\n",
      "Finalizing training ops...\n",
      "Initializing metrics...\n",
      "Training for 25000 kimg...\n",
      "\n",
      "tick 0     kimg 0.0      time 2m 33s       sec/tick 28.0    sec/kimg 1751.20 maintenance 125.4  gpumem 10.2  augment 0.000\n",
      "tick 1     kimg 4.0      time 35m 48s      sec/tick 1979.4  sec/kimg 494.85  maintenance 15.6   gpumem 10.2  augment 0.006\n",
      "tick 2     kimg 8.0      time 1h 08m 50s   sec/tick 1981.2  sec/kimg 495.31  maintenance 0.0    gpumem 10.2  augment 0.009\n",
      "tick 3     kimg 12.0     time 1h 41m 51s   sec/tick 1981.7  sec/kimg 495.41  maintenance 0.0    gpumem 10.2  augment 0.011\n",
      "tick 4     kimg 16.0     time 2h 14m 55s   sec/tick 1983.3  sec/kimg 495.81  maintenance 0.0    gpumem 10.2  augment 0.016\n",
      "tick 5     kimg 20.0     time 2h 47m 59s   sec/tick 1984.5  sec/kimg 496.12  maintenance 0.0    gpumem 10.2  augment 0.022\n",
      "tick 6     kimg 24.0     time 3h 21m 10s   sec/tick 1987.3  sec/kimg 496.82  maintenance 3.8    gpumem 10.2  augment 0.028\n",
      "tick 7     kimg 28.0     time 3h 54m 18s   sec/tick 1987.7  sec/kimg 496.93  maintenance 0.0    gpumem 10.2  augment 0.033\n",
      "tick 8     kimg 32.0     time 4h 27m 28s   sec/tick 1990.4  sec/kimg 497.60  maintenance 0.0    gpumem 10.2  augment 0.038\n",
      "tick 9     kimg 36.0     time 5h 00m 38s   sec/tick 1990.1  sec/kimg 497.52  maintenance 0.0    gpumem 10.2  augment 0.039\n",
      "tick 10    kimg 40.0     time 5h 33m 49s   sec/tick 1990.7  sec/kimg 497.67  maintenance 0.0    gpumem 10.2  augment 0.045\n",
      "tick 11    kimg 44.0     time 6h 07m 05s   sec/tick 1991.4  sec/kimg 497.86  maintenance 4.4    gpumem 10.2  augment 0.048\n",
      "tick 12    kimg 48.0     time 6h 40m 19s   sec/tick 1993.7  sec/kimg 498.42  maintenance 0.0    gpumem 10.2  augment 0.052\n",
      "tick 13    kimg 52.0     time 7h 13m 34s   sec/tick 1995.2  sec/kimg 498.79  maintenance 0.0    gpumem 10.2  augment 0.063\n",
      "tick 14    kimg 56.0     time 7h 46m 52s   sec/tick 1998.5  sec/kimg 499.61  maintenance 0.0    gpumem 10.2  augment 0.068\n",
      "tick 15    kimg 60.0     time 8h 20m 11s   sec/tick 1998.3  sec/kimg 499.57  maintenance 0.0    gpumem 10.2  augment 0.075\n",
      "tick 16    kimg 64.0     time 8h 53m 36s   sec/tick 2001.8  sec/kimg 500.45  maintenance 3.9    gpumem 10.2  augment 0.082\n",
      "tick 17    kimg 68.0     time 9h 26m 58s   sec/tick 2002.2  sec/kimg 500.55  maintenance 0.0    gpumem 10.2  augment 0.090\n",
      "tick 18    kimg 72.0     time 10h 00m 24s  sec/tick 2005.4  sec/kimg 501.35  maintenance 0.0    gpumem 10.2  augment 0.098\n",
      "tick 19    kimg 76.0     time 10h 33m 49s  sec/tick 2005.3  sec/kimg 501.32  maintenance 0.0    gpumem 10.2  augment 0.104\n",
      "tick 20    kimg 80.0     time 11h 07m 16s  sec/tick 2006.9  sec/kimg 501.73  maintenance 0.0    gpumem 10.2  augment 0.104\n",
      "tick 21    kimg 84.0     time 11h 40m 47s  sec/tick 2006.9  sec/kimg 501.73  maintenance 4.1    gpumem 10.2  augment 0.108\n",
      "tick 22    kimg 88.0     time 12h 14m 16s  sec/tick 2009.1  sec/kimg 502.26  maintenance 0.0    gpumem 10.2  augment 0.108\n",
      "tick 23    kimg 92.0     time 12h 47m 45s  sec/tick 2008.7  sec/kimg 502.18  maintenance 0.0    gpumem 10.2  augment 0.112\n",
      "tick 24    kimg 96.0     time 13h 21m 16s  sec/tick 2011.5  sec/kimg 502.87  maintenance 0.0    gpumem 10.2  augment 0.120\n",
      "tick 25    kimg 100.0    time 13h 54m 46s  sec/tick 2010.1  sec/kimg 502.52  maintenance 0.0    gpumem 10.2  augment 0.122\n",
      "tick 26    kimg 104.0    time 14h 28m 22s  sec/tick 2011.5  sec/kimg 502.86  maintenance 3.9    gpumem 10.2  augment 0.122\n",
      "tick 27    kimg 108.0    time 15h 01m 53s  sec/tick 2010.8  sec/kimg 502.71  maintenance 0.0    gpumem 10.2  augment 0.125\n",
      "tick 28    kimg 112.0    time 15h 35m 26s  sec/tick 2013.7  sec/kimg 503.42  maintenance 0.0    gpumem 10.2  augment 0.128\n",
      "tick 29    kimg 116.0    time 16h 08m 59s  sec/tick 2012.9  sec/kimg 503.23  maintenance 0.0    gpumem 10.2  augment 0.129\n",
      "tick 30    kimg 120.0    time 16h 42m 32s  sec/tick 2013.0  sec/kimg 503.26  maintenance 0.0    gpumem 10.2  augment 0.130\n",
      "tick 31    kimg 124.0    time 17h 16m 09s  sec/tick 2012.9  sec/kimg 503.22  maintenance 4.0    gpumem 10.2  augment 0.134\n",
      "tick 32    kimg 128.0    time 17h 49m 43s  sec/tick 2013.4  sec/kimg 503.34  maintenance 0.0    gpumem 10.2  augment 0.136\n",
      "tick 33    kimg 132.0    time 18h 23m 16s  sec/tick 2013.4  sec/kimg 503.36  maintenance 0.0    gpumem 10.2  augment 0.139\n",
      "tick 34    kimg 136.0    time 18h 56m 49s  sec/tick 2013.2  sec/kimg 503.29  maintenance 0.0    gpumem 10.2  augment 0.134\n"
     ]
    }
   ],
   "source": [
    "#this name must EXACTLY match the dataset name you used when creating the .tfrecords file\n",
    "dataset_name = \"artists_tf\" # abstract_tf\n",
    "#how often should the model generate samples and a .pkl file\n",
    "snapshot_count = 5\n",
    "#should the images be mirrored left to right?\n",
    "mirrored = True\n",
    "#should the images be mirrored top to bottom?\n",
    "mirroredY = True\n",
    "\"\"\"Since mirrored vertically and horizontally, we now have x4 as many records.\"\"\"\n",
    "\n",
    "#metrics? \n",
    "metric_list = None\n",
    "#augments\n",
    "# augs = \"bgcfnc\"\n",
    "\n",
    "#\n",
    "# this is the most important cell to update\n",
    "#\n",
    "# running it for the first time? set it to ffhq(+resolution)\n",
    "# resuming? get the path to your latest .pkl file and use that\n",
    "resume_from = \"/content/drive/MyDrive/results_artists_gan/00002-artists_tf-mirror-mirrory-11gb-gpu-bgcfnc-resumecustom/network-snapshot-000060.pkl\" # Location of latest .pkl weights. --resume={resume_from} \n",
    "\n",
    "!python train.py --outdir=/content/drive/MyDrive/results_artists_gan --snap={snapshot_count} --cfg=11gb-gpu --data=/content/drive/MyDrive/{dataset_name} --mirror={mirrored} --mirrory={mirroredY} --metrics={metric_list} --augpipe=bgcfnc --resume={resume_from} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kWRzjrLMxBGT"
   },
   "source": [
    "While it’s training...\n",
    "Once the above cell is running you should be training!\n",
    "\n",
    "Don’t close this tab! Colab needs to be open and running in order to continue training. Every 15min 256x256x3 or 35min 1024x1024x3 on P100 (~45 min for T4) or so a new line should get added to your output, indicated its still training. Depending on you snapshot_count setting you should see the results folder in your Google drive folder fill with both samples (fakesXXXXXx.jpg) and model weights (network-snapshot-XXXXXX.pkl). The samples are worth looking at while it trains but don’t get too worried about each individual sample.\n",
    "\n",
    "If you chose a metric, you will also see scores for each snapshot. Don’t obsess over these! they are a guide, it can go up or down slightly for each snapshot. What you want to see is a gradual lowering of the score over time.\n",
    "\n",
    "Once Colab shuts off, you can Reconnect the notebook and re-run every cell from top to bottom. Make sure you update the resume_from path to continue training from the latest model."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "StyleGan2-ADA_Custom_Abstract.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
